# 实时转录准确性优化指南

## 概述

本文档描述Life Coach实时转录系统的准确性优化方案，包括音频预处理、VAD参数调优、上下文利用等多个方面。

## 优化清单

### 1. 音频预处理 ✅

**问题**：原始音频可能包含噪声、音量不均等问题，影响识别准确率。

**解决方案**：

- **音量归一化**：将音频归一化到配置的目标幅度（默认0.95），防止过小或过大
- **高通滤波**：使用一阶差分近似高通滤波器，去除低频噪声（如环境嗡嗡声）
- **静音过滤**：检测RMS值，过滤掉几乎无声的片段

**配置参数** (`src/config.py`):

```python
# 音频归一化
AUDIO_NORMALIZE_ENABLED = True  # 是否启用音量归一化
AUDIO_NORMALIZE_TARGET = 0.95   # 归一化目标幅度（0-1）

# 音频降噪
AUDIO_HIGHPASS_FILTER_ENABLED = True  # 是否启用高通滤波
AUDIO_HIGHPASS_ALPHA = 0.95           # 高通滤波系数（0.9-0.99，越大越温和）

# 音频质量检查
AUDIO_MIN_RMS_THRESHOLD = 0.001  # 最小RMS阈值，低于此值跳过片段
```

**实现位置**：
- `src/audio_recorder_real.py::_preprocess_audio()`
- `src/audio_recorder_real.py::_on_vad_segment()`

### 2. 音频质量监控 ✅

**问题**：需要了解每个片段的音频质量，便于调试和优化。

**解决方案**：

- 计算每个片段的 **RMS**（均方根，表示平均音量）
- 计算每个片段的 **Peak**（峰值，表示最大音量）
- 在日志中输出这些指标

**示例输出**：

```
[VAD分段] 第 3 段: duration=2.30s, samples=36800, RMS=0.0156, Peak=0.1234
```

**判断标准**：
- RMS < 0.001：几乎无声，应跳过
- RMS 0.001-0.01：音量较小，可能识别困难
- RMS 0.01-0.1：正常说话音量
- RMS > 0.1：大声或距离麦克风很近

### 3. 上下文信息利用 ✅

**问题**：Paraformer流式识别每个片段是独立的，缺少前后文参考。

**解决方案**：

- 保留最近N个片段的识别结果（默认2个）
- 在识别新片段时，在日志中显示上下文（未来可用于hotwords）
- 自动更新上下文历史

**配置参数**：

```python
ASR_CONTEXT_SIZE = 2     # 保留前N个分段的上下文
ASR_USE_CONTEXT = True   # 是否使用上下文提示
```

**注意**：当前Paraformer模型不直接支持hotwords，上下文主要用于日志记录和future功能扩展。

**实现位置**：
- `src/asr_sherpa.py::__init__()` - 初始化context_history
- `src/asr_sherpa.py::transcribe()` - 管理上下文历史

### 4. 实时转录质量检查 ✅

**问题**：无效的音频片段会浪费计算资源并产生错误的空白结果。

**解决方案**：

- 在worker线程中检查音频片段的RMS
- 跳过音量过低的片段
- 在日志中记录跳过原因

**实现位置**：
- `src/realtime_transcriber.py::_transcribe_worker()`

### 5. VAD参数优化（待调优）

**当前配置** (`src/config.py`):

```python
REALTIME_MIN_SILENCE_DURATION = 1.2  # 静音触发时长（秒）
REALTIME_MAX_SEGMENT_DURATION = 10.0  # 最大分段时长（秒）
REALTIME_MIN_SEGMENT_DURATION = 0.5   # 最小分段时长（秒）
```

**调优建议**：

根据实际使用场景调整：

| 场景 | min_silence | max_segment | 说明 |
|------|-------------|-------------|------|
| 快速对话 | 0.8-1.0s | 8s | 短句多，快速反馈 |
| 正常对话（当前） | 1.2s | 10s | 平衡准确性和延迟 |
| 演讲/讲座 | 1.5-2.0s | 15s | 长句多，减少误触发 |

**调整方法**：

1. 修改 `src/config.py` 中的参数
2. 或通过环境变量设置：
   ```bash
   export REALTIME_MIN_SILENCE_DURATION=1.0
   export REALTIME_MAX_SEGMENT_DURATION=8.0
   ```

## 性能影响分析

### 音频预处理开销

- **归一化**：O(n)，耗时约 0.1-0.5ms（对16kHz 2秒音频）
- **高通滤波**：O(n)，耗时约 0.5-1ms
- **总开销**：<2ms，可忽略

### 质量检查开销

- **RMS计算**：O(n)，耗时<0.5ms
- **Peak计算**：O(n)，耗时<0.5ms
- **总开销**：<1ms，可忽略

### 上下文管理开销

- 仅涉及字符串操作和列表管理
- 耗时<0.1ms，可忽略

**结论**：所有优化措施的总开销<3ms，对实时转录（通常耗时500-2000ms）影响可忽略。

## 测试与验证

### 1. 基础功能测试

```bash
# 启动服务
python main.py

# 在Web界面进行录音测试
# 观察日志输出
```

**预期日志**：

```
[VAD] 第 1 段: start=0.50s, duration=2.30s, samples=36800
[VAD分段] 第 1 段: duration=2.30s, samples=36800, RMS=0.0234, Peak=0.1567
[实时转录] 开始转录分段 #0（排队: 0.02秒）
[ASR上下文] 
[ASR] 识别结果: 今天天气怎么样
```

### 2. 音频质量测试

**低音量测试**：
- 距离麦克风较远或小声说话
- 应看到RMS值较低（0.001-0.01）
- 如果RMS < 0.001，应看到"音量过低，跳过该片段"

**正常音量测试**：
- 正常距离和音量说话
- RMS应在0.01-0.1范围内
- 识别准确率应较高

**高音量测试**：
- 大声说话或距离麦克风很近
- RMS > 0.1，Peak可能接近1.0
- 识别准确率应保持良好

### 3. 降噪效果测试

**环境噪音测试**：
- 在有背景噪音的环境中录音（如风扇、空调）
- 观察高通滤波是否改善识别
- 对比开启/关闭滤波的识别结果

**设置方法**：

```python
# 关闭高通滤波（在config.py中）
AUDIO_HIGHPASS_FILTER_ENABLED = False
```

### 4. 上下文效果测试

**连续对话测试**：
- 说一系列相关的句子
- 观察日志中的上下文输出
- 评估是否有助于理解（当前仅记录，未来可用于hotwords）

## 故障排查

### 问题1：所有片段都被跳过

**现象**：
```
[VAD分段] 警告: 音量过低 (RMS=0.0003 < 0.001)，跳过该片段
```

**原因**：
- 麦克风未正确连接
- 麦克风音量设置过低
- 麦克风选择错误

**解决**：
1. 检查麦克风连接：`arecord -l`
2. 调整麦克风音量：`alsamixer`
3. 如果确认麦克风正常但仍被跳过，降低阈值：
   ```python
   AUDIO_MIN_RMS_THRESHOLD = 0.0001  # 降低10倍
   ```

### 问题2：识别结果不准确

**可能原因**：

1. **音频质量问题**
   - 检查RMS和Peak值
   - 尝试调整麦克风距离和音量

2. **VAD分段问题**
   - 句子被截断
   - 调整 `REALTIME_MIN_SILENCE_DURATION`

3. **模型限制**
   - Paraformer对某些场景识别较差
   - 考虑使用更大的模型

### 问题3：预处理后音质变差

**现象**：识别准确率下降

**可能原因**：
- 高通滤波过强，去除了有用频率
- 归一化导致背景噪声被放大

**解决**：

1. 调整高通滤波系数（更温和）：
   ```python
   AUDIO_HIGHPASS_ALPHA = 0.98  # 从0.95提高到0.98
   ```

2. 关闭归一化：
   ```python
   AUDIO_NORMALIZE_ENABLED = False
   ```

3. 降低归一化目标：
   ```python
   AUDIO_NORMALIZE_TARGET = 0.7  # 从0.95降低到0.7
   ```

## 进一步优化方向

### 1. 谱减法降噪（未实现）

使用FFT进行频域降噪，效果更好但开销更大。

**预期效果**：提升10-20%准确率
**预期开销**：+10-50ms每片段

### 2. VAD模型fine-tuning（未实现）

使用实际录音数据微调Silero VAD。

**预期效果**：减少误触发，更准确的端点检测
**实现复杂度**：高

### 3. Hotwords支持（待Paraformer支持）

当Paraformer支持hotwords后，可利用上下文提升准确率。

**预期效果**：提升5-15%准确率（专有名词、术语）
**当前状态**：代码已预留接口，等待模型支持

### 4. 多模型集成（未实现）

同时运行多个ASR模型，结果投票或融合。

**预期效果**：提升准确率，但计算开销翻倍
**适用场景**：对准确率要求极高的场景

## 配置总结

| 参数 | 默认值 | 说明 | 调优建议 |
|------|--------|------|----------|
| `AUDIO_NORMALIZE_ENABLED` | True | 启用音量归一化 | 通常保持开启 |
| `AUDIO_NORMALIZE_TARGET` | 0.95 | 归一化目标幅度 | 0.7-0.95，根据环境调整 |
| `AUDIO_HIGHPASS_FILTER_ENABLED` | True | 启用高通滤波 | 噪音环境开启，安静环境可关闭 |
| `AUDIO_HIGHPASS_ALPHA` | 0.95 | 滤波系数 | 0.90-0.98，越高越温和 |
| `AUDIO_MIN_RMS_THRESHOLD` | 0.001 | 最小RMS阈值 | 0.0001-0.01，根据麦克风灵敏度调整 |
| `ASR_CONTEXT_SIZE` | 2 | 上下文历史大小 | 1-5，越大记忆越长 |
| `ASR_USE_CONTEXT` | True | 使用上下文 | 保持开启 |
| `REALTIME_MIN_SILENCE_DURATION` | 1.2 | 静音触发时长 | 0.8-2.0s，根据说话习惯调整 |
| `REALTIME_MAX_SEGMENT_DURATION` | 10.0 | 最大分段时长 | 8-15s，越长延迟越高 |

## 更新日志

- **2026-01-25**：初始版本，实现音频预处理、质量监控、上下文管理

